"""
FallSense - Streamlit Application
·ª®ng d·ª•ng ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ s·ª≠ d·ª•ng YOLOv7 v·ªõi giao di·ªán Streamlit
"""

import streamlit as st
import cv2
import numpy as np
import os
import time
from pathlib import Path
from PIL import Image
import tempfile

# Import c√°c module t·ª´ d·ª± √°n FallSense
from src.Fall_detection import FallDetector

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="FallSense - Ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ",
    page_icon="üö®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Kh·ªüi t·∫°o session state
if 'fall_detector' not in st.session_state:
    st.session_state.fall_detector = None
if 'camera_active' not in st.session_state:
    st.session_state.camera_active = False
if 'video_capture' not in st.session_state:
    st.session_state.video_capture = None
if 'recording' not in st.session_state:
    st.session_state.recording = False
if 'video_writer' not in st.session_state:
    st.session_state.video_writer = None
if 'save_folder' not in st.session_state:
    st.session_state.save_folder = None
if 'show_keypoints' not in st.session_state:
    st.session_state.show_keypoints = False
if 'flip_horizontal' not in st.session_state:
    st.session_state.flip_horizontal = False
if 'last_fall_time' not in st.session_state:
    st.session_state.last_fall_time = None

# Ti√™u ƒë·ªÅ ch√≠nh
st.title("üö® FallSense - Ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ")
st.markdown("---")

# Sidebar - C√†i ƒë·∫∑t
with st.sidebar:
    st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
    
    # Ch·ªçn ch·∫ø ƒë·ªô
    mode = st.radio(
        "Ch·ªçn ch·∫ø ƒë·ªô:",
        ["üìπ Camera", "üìÅ Video File", "üñºÔ∏è Image"],
        index=0
    )
    
    # T√πy ch·ªçn hi·ªÉn th·ªã keypoints
    st.session_state.show_keypoints = st.checkbox(
        "Hi·ªÉn th·ªã keypoints (skeleton)",
        value=st.session_state.show_keypoints
    )
    
    # T√πy ch·ªçn l·∫≠t ngang
    st.session_state.flip_horizontal = st.checkbox(
        "L·∫≠t ngang camera",
        value=st.session_state.flip_horizontal
    )
    
    # Ch·ªçn th∆∞ m·ª•c l∆∞u
    auto_record = st.checkbox("T·ª± ƒë·ªông ghi khi ph√°t hi·ªán ng√£", value=False)
    
    if auto_record:
        save_folder_input = st.text_input(
            "Th∆∞ m·ª•c l∆∞u video:",
            value=st.session_state.save_folder or "./recordings",
            help="Nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ƒë·ªÉ l∆∞u video khi ph√°t hi·ªán ng√£"
        )
        if save_folder_input:
            st.session_state.save_folder = save_folder_input
            os.makedirs(st.session_state.save_folder, exist_ok=True)
    
    st.markdown("---")
    st.header("‚ÑπÔ∏è Th√¥ng tin")
    st.info("""
    **FallSense** s·ª≠ d·ª•ng m√¥ h√¨nh YOLOv7 ƒë·ªÉ ph√°t hi·ªán:
    - Ng√£ (Fall detection)
    - ƒê·ªôt qu·ªµ (Stroke detection)
    
    ·ª®ng d·ª•ng c√≥ th·ªÉ ho·∫°t ƒë·ªông v·ªõi:
    - Camera tr·ª±c ti·∫øp
    - Video file
    - H√¨nh ·∫£nh
    """)

# Kh·ªüi t·∫°o model
@st.cache_resource
def load_model():
    """T·∫£i m√¥ h√¨nh YOLOv7 m·ªôt l·∫ßn v√† cache"""
    model_path = "weights/fall_detection_person.pt"
    if not os.path.exists(model_path):
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y model weights t·∫°i: {model_path}")
        st.stop()
    
    device = "cuda" if cv2.cuda.getCudaEnabledDeviceCount() > 0 else "cpu"
    detector = FallDetector(
        model_path,
        device,
        show_keypoints=st.session_state.show_keypoints
    )
    return detector

# T·∫£i model
if st.session_state.fall_detector is None:
    with st.spinner("ƒêang t·∫£i m√¥ h√¨nh YOLOv7..."):
        try:
            st.session_state.fall_detector = load_model()
            st.session_state.fall_detector.show_keypoints = st.session_state.show_keypoints
            st.success("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
            st.stop()

# C·∫≠p nh·∫≠t show_keypoints cho detector
if st.session_state.fall_detector:
    st.session_state.fall_detector.show_keypoints = st.session_state.show_keypoints

# H√†m x·ª≠ l√Ω frame
def process_frame(frame, orig_img=None):
    """X·ª≠ l√Ω m·ªôt frame v√† tr·∫£ v·ªÅ k·∫øt qu·∫£"""
    if st.session_state.flip_horizontal:
        frame = cv2.flip(frame, 1)
    
    if orig_img is None:
        orig_img = frame.copy()
    
    # T·∫°o padded image ƒë·ªÉ hi·ªÉn th·ªã
    height, width = frame.shape[:2]
    padded_img = frame.copy()
    
    # Ch·∫°y inference
    img_result, is_fall = st.session_state.fall_detector.inference_and_draw_on_display(
        orig_img, padded_img, 1.0, 0, 0, width, height
    )
    
    return img_result, is_fall

# H√†m b·∫Øt ƒë·∫ßu ghi video
def start_recording(frame):
    """B·∫Øt ƒë·∫ßu ghi video khi ph√°t hi·ªán ng√£"""
    if not st.session_state.recording and st.session_state.save_folder:
        st.session_state.recording = True
        filename = time.strftime("recording_%Y_%m_%d_%H_%M_%S.mp4")
        save_path = os.path.join(st.session_state.save_folder, filename)
        height, width = frame.shape[:2]
        fps = 20
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        st.session_state.video_writer = cv2.VideoWriter(save_path, fourcc, fps, (width, height))
        return True
    return False

# H√†m d·ª´ng ghi video
def stop_recording():
    """D·ª´ng ghi video"""
    if st.session_state.recording and st.session_state.video_writer:
        st.session_state.video_writer.release()
        st.session_state.video_writer = None
        st.session_state.recording = False
        return True
    return False

# X·ª≠ l√Ω theo ch·∫ø ƒë·ªô
if mode == "üìπ Camera":
    st.subheader("üìπ Ch·∫ø ƒë·ªô Camera")
    
    # S·ª≠ d·ª•ng st.camera_input cho camera ƒë∆°n gi·∫£n h∆°n
    camera_input = st.camera_input("B·∫≠t camera ƒë·ªÉ b·∫Øt ƒë·∫ßu")
    
    if camera_input is not None:
        try:
            # Chuy·ªÉn ƒë·ªïi t·ª´ PIL Image sang numpy array
            # st.camera_input tr·∫£ v·ªÅ PIL Image ho·∫∑c BytesIO
            if isinstance(camera_input, Image.Image):
                # Chuy·ªÉn PIL Image sang numpy array (RGB format)
                img_array = np.array(camera_input.convert('RGB'))
            else:
                # N·∫øu l√† BytesIO, ƒë·ªçc l·∫°i b·∫±ng PIL
                camera_input.seek(0)  # Reset v·ªÅ ƒë·∫ßu file
                img_pil = Image.open(camera_input)
                img_array = np.array(img_pil.convert('RGB'))
            
            # Ki·ªÉm tra ƒë·ªãnh d·∫°ng v√† chuy·ªÉn ƒë·ªïi
            if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                # ƒê·∫£m b·∫£o l√† uint8
                if img_array.dtype != np.uint8:
                    if img_array.max() <= 1.0:
                        img_array = (img_array * 255).astype(np.uint8)
                    else:
                        img_array = img_array.astype(np.uint8)
                
                # Chuy·ªÉn ƒë·ªïi RGB sang BGR cho OpenCV
                img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            else:
                st.error(f"‚ùå L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω h√¨nh ·∫£nh t·ª´ camera. Shape: {img_array.shape if 'img_array' in locals() else 'N/A'}")
                st.stop()
            
            # X·ª≠ l√Ω frame
            img_result, is_fall = process_frame(img_bgr)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            col1, col2 = st.columns([2, 1])
            
            with col1:
                img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)
                st.image(img_result_rgb, caption="K·∫øt qu·∫£ ph√°t hi·ªán", use_container_width=True)
            
            with col2:
                # Hi·ªÉn th·ªã tr·∫°ng th√°i
                if is_fall:
                    st.error("üö® **PH√ÅT HI·ªÜN NG√É!**")
                    st.balloons()  # Hi·ªáu ·ª©ng khi ph√°t hi·ªán ng√£
                else:
                    st.success("‚úÖ **B√¨nh th∆∞·ªùng**")
                
                # X·ª≠ l√Ω ghi video t·ª± ƒë·ªông
                if auto_record and st.session_state.save_folder:
                    if is_fall:
                        if not st.session_state.recording:
                            start_recording(img_bgr)
                            st.session_state.last_fall_time = time.time()
                        if st.session_state.video_writer:
                            st.session_state.video_writer.write(img_bgr)
                    else:
                        # D·ª´ng ghi sau 2 gi√¢y kh√¥ng ph√°t hi·ªán ng√£
                        if st.session_state.recording:
                            if st.session_state.last_fall_time:
                                if time.time() - st.session_state.last_fall_time > 2:
                                    stop_recording()
                    
                    # Hi·ªÉn th·ªã tr·∫°ng th√°i ghi
                    if st.session_state.recording:
                        st.warning("üî¥ ƒêang ghi video...")
                    else:
                        st.info("‚è∏Ô∏è Kh√¥ng ghi")
        except Exception as e:
            st.error(f"‚ùå L·ªói x·ª≠ l√Ω camera: {str(e)}")
            st.exception(e)

elif mode == "üìÅ Video File":
    st.subheader("üìÅ Ch·∫ø ƒë·ªô Video File")
    
    uploaded_file = st.file_uploader(
        "Ch·ªçn file video",
        type=['mp4', 'avi', 'mov', 'mkv']
    )
    
    if uploaded_file is not None:
        # L∆∞u file t·∫°m
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_file.read())
        tfile.close()
        
        # M·ªü video
        video_capture = cv2.VideoCapture(tfile.name)
        
        if not video_capture.isOpened():
            st.error("‚ùå Kh√¥ng th·ªÉ m·ªü file video.")
        else:
            st.success("‚úÖ Video ƒë√£ ƒë∆∞·ª£c t·∫£i!")
            
            # L·∫•y th√¥ng tin video
            fps = int(video_capture.get(cv2.CAP_PROP_FPS))
            total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # Thanh ti·∫øn tr√¨nh
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Hi·ªÉn th·ªã video
            video_placeholder = st.empty()
            
            frame_count = 0
            while True:
                ret, frame = video_capture.read()
                if not ret:
                    break
                
                # X·ª≠ l√Ω frame
                img_result, is_fall = process_frame(frame)
                
                # Hi·ªÉn th·ªã
                img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)
                video_placeholder.image(img_result_rgb, channels="RGB", use_container_width=True)
                
                # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh
                frame_count += 1
                progress = frame_count / total_frames
                progress_bar.progress(progress)
                
                # Hi·ªÉn th·ªã tr·∫°ng th√°i
                if is_fall:
                    status_text.error(f"üö® **PH√ÅT HI·ªÜN NG√É!** - Frame {frame_count}/{total_frames}")
                else:
                    status_text.success(f"‚úÖ **B√¨nh th∆∞·ªùng** - Frame {frame_count}/{total_frames}")
                
                time.sleep(1.0 / fps)  # Gi·ªØ t·ªëc ƒë·ªô video g·ªëc
            
            video_capture.release()
            os.unlink(tfile.name)
            st.success("‚úÖ ƒê√£ x·ª≠ l√Ω xong video!")

elif mode == "üñºÔ∏è Image":
    st.subheader("üñºÔ∏è Ch·∫ø ƒë·ªô H√¨nh ·∫£nh")
    
    uploaded_file = st.file_uploader(
        "Ch·ªçn h√¨nh ·∫£nh",
        type=['jpg', 'jpeg', 'png']
    )
    
    if uploaded_file is not None:
        # ƒê·ªçc h√¨nh ·∫£nh
        image = Image.open(uploaded_file)
        img_array = np.array(image)
        
        # Chuy·ªÉn ƒë·ªïi RGB sang BGR cho OpenCV
        if len(img_array.shape) == 3:
            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = img_array
        
        # X·ª≠ l√Ω
        img_result, is_fall = process_frame(img_bgr)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(image, caption="H√¨nh ·∫£nh g·ªëc", use_container_width=True)
        
        with col2:
            img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)
            st.image(img_result_rgb, caption="K·∫øt qu·∫£ ph√°t hi·ªán", use_container_width=True)
        
        # Hi·ªÉn th·ªã tr·∫°ng th√°i
        if is_fall:
            st.error("üö® **PH√ÅT HI·ªÜN NG√É!**")
        else:
            st.success("‚úÖ **B√¨nh th∆∞·ªùng**")

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        <p>FallSense - Ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ s·ª≠ d·ª•ng YOLOv7</p>
        <p>Powered by PyTorch & Streamlit</p>
    </div>
    """,
    unsafe_allow_html=True
)

