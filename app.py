"""
FallSense - Streamlit Application
·ª®ng d·ª•ng ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ s·ª≠ d·ª•ng YOLOv7 v·ªõi giao di·ªán Streamlit
"""

import streamlit as st
import cv2
import numpy as np
import os
import time
from pathlib import Path
from PIL import Image
import tempfile
import threading
from datetime import datetime

# Import c√°c module t·ª´ d·ª± √°n FallSense
from src.Fall_detection import FallDetector

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="FallSense - Ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ",
    page_icon="üö®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Kh·ªüi t·∫°o session state
if 'fall_detector' not in st.session_state:
    st.session_state.fall_detector = None
if 'camera_active' not in st.session_state:
    st.session_state.camera_active = False
if 'video_capture' not in st.session_state:
    st.session_state.video_capture = None
if 'recording' not in st.session_state:
    st.session_state.recording = False
if 'video_writer' not in st.session_state:
    st.session_state.video_writer = None
if 'save_folder' not in st.session_state:
    st.session_state.save_folder = None
if 'show_keypoints' not in st.session_state:
    st.session_state.show_keypoints = False
if 'flip_horizontal' not in st.session_state:
    st.session_state.flip_horizontal = False
if 'last_fall_time' not in st.session_state:
    st.session_state.last_fall_time = None
if 'fall_count' not in st.session_state:
    st.session_state.fall_count = 0
if 'fall_history' not in st.session_state:
    st.session_state.fall_history = []
if 'current_frame' not in st.session_state:
    st.session_state.current_frame = None
if 'current_status' not in st.session_state:
    st.session_state.current_status = "Ch∆∞a b·∫Øt ƒë·∫ßu"

# Ti√™u ƒë·ªÅ ch√≠nh
st.title("üö® FallSense - Ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ")
st.markdown("---")

# Sidebar - C√†i ƒë·∫∑t
with st.sidebar:
    st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
    
    # Ch·ªçn ch·∫ø ƒë·ªô
    mode = st.radio(
        "Ch·ªçn ch·∫ø ƒë·ªô:",
        ["üìπ Camera", "üìÅ Video File", "üñºÔ∏è Image"],
        index=0
    )
    
    # T√πy ch·ªçn hi·ªÉn th·ªã keypoints
    st.session_state.show_keypoints = st.checkbox(
        "Hi·ªÉn th·ªã keypoints (skeleton)",
        value=st.session_state.show_keypoints
    )
    
    # T√πy ch·ªçn l·∫≠t ngang
    st.session_state.flip_horizontal = st.checkbox(
        "L·∫≠t ngang camera",
        value=st.session_state.flip_horizontal
    )
    
    # Ch·ªçn th∆∞ m·ª•c l∆∞u
    auto_record = st.checkbox("T·ª± ƒë·ªông ghi khi ph√°t hi·ªán ng√£", value=False)
    
    if auto_record:
        save_folder_input = st.text_input(
            "Th∆∞ m·ª•c l∆∞u video:",
            value=st.session_state.save_folder or "./recordings",
            help="Nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ƒë·ªÉ l∆∞u video khi ph√°t hi·ªán ng√£"
        )
        if save_folder_input:
            st.session_state.save_folder = save_folder_input
            os.makedirs(st.session_state.save_folder, exist_ok=True)
    
    st.markdown("---")
    st.header("üìä Th·ªëng k√™")
    st.metric("S·ªë l·∫ßn ph√°t hi·ªán ng√£", st.session_state.fall_count)
    
    if st.session_state.fall_history:
        st.subheader("L·ªãch s·ª≠ ph√°t hi·ªán")
        for i, fall_time in enumerate(reversed(st.session_state.fall_history[-5:]), 1):
            st.text(f"{i}. {fall_time}")
    
    st.markdown("---")
    st.header("‚ÑπÔ∏è Th√¥ng tin")
    st.info("""
    **FallSense** s·ª≠ d·ª•ng m√¥ h√¨nh YOLOv7 ƒë·ªÉ ph√°t hi·ªán:
    - Ng√£ (Fall detection)
    - ƒê·ªôt qu·ªµ (Stroke detection)
    
    ·ª®ng d·ª•ng c√≥ th·ªÉ ho·∫°t ƒë·ªông v·ªõi:
    - Camera tr·ª±c ti·∫øp
    - Video file
    - H√¨nh ·∫£nh
    """)

# Kh·ªüi t·∫°o model
@st.cache_resource
def load_model():
    """T·∫£i m√¥ h√¨nh YOLOv7 m·ªôt l·∫ßn v√† cache"""
    model_path = "weights/fall_detection_person.pt"
    if not os.path.exists(model_path):
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y model weights t·∫°i: {model_path}")
        st.stop()
    
    device = "cuda" if cv2.cuda.getCudaEnabledDeviceCount() > 0 else "cpu"
    detector = FallDetector(
        model_path,
        device,
        show_keypoints=st.session_state.show_keypoints
    )
    return detector

# T·∫£i model
if st.session_state.fall_detector is None:
    with st.spinner("ƒêang t·∫£i m√¥ h√¨nh YOLOv7..."):
        try:
            st.session_state.fall_detector = load_model()
            st.session_state.fall_detector.show_keypoints = st.session_state.show_keypoints
            st.success("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
            st.exception(e)
            st.stop()

# C·∫≠p nh·∫≠t show_keypoints cho detector
if st.session_state.fall_detector:
    st.session_state.fall_detector.show_keypoints = st.session_state.show_keypoints

# H√†m x·ª≠ l√Ω frame
def process_frame(frame, orig_img=None):
    """X·ª≠ l√Ω m·ªôt frame v√† tr·∫£ v·ªÅ k·∫øt qu·∫£"""
    if st.session_state.flip_horizontal:
        frame = cv2.flip(frame, 1)
    
    if orig_img is None:
        orig_img = frame.copy()
    
    # L·∫•y k√≠ch th∆∞·ªõc frame
    height, width = frame.shape[:2]
    
    # T·∫°o padded image ƒë·ªÉ hi·ªÉn th·ªã (gi·ªØ nguy√™n k√≠ch th∆∞·ªõc)
    padded_img = frame.copy()
    
    # Ch·∫°y inference v·ªõi scale = 1.0, pad = 0 v√¨ kh√¥ng resize
    img_result, is_fall = st.session_state.fall_detector.inference_and_draw_on_display(
        orig_img, padded_img, 1.0, 0, 0, width, height
    )
    
    # Th√™m text c·∫£nh b√°o n·∫øu ph√°t hi·ªán ng√£
    if is_fall:
        # V·∫Ω text c·∫£nh b√°o l·ªõn
        text = "PHAT HIEN NGA!"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1.5
        thickness = 3
        color = (0, 0, 255)  # ƒê·ªè
        
        # T√≠nh to√°n v·ªã tr√≠ text (gi·ªØa m√†n h√¨nh)
        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
        x = (width - text_width) // 2
        y = (height + text_height) // 2
        
        # V·∫Ω background cho text
        cv2.rectangle(img_result, 
                     (x - 10, y - text_height - 10), 
                     (x + text_width + 10, y + baseline + 10), 
                     (0, 0, 0), -1)
        
        # V·∫Ω text
        cv2.putText(img_result, text, (x, y), font, font_scale, color, thickness, cv2.LINE_AA)
        
        # V·∫Ω border ƒë·ªè
        cv2.rectangle(img_result, (0, 0), (width-1, height-1), (0, 0, 255), 10)
    
    return img_result, is_fall

# H√†m b·∫Øt ƒë·∫ßu ghi video
def start_recording(frame):
    """B·∫Øt ƒë·∫ßu ghi video khi ph√°t hi·ªán ng√£"""
    if not st.session_state.recording and st.session_state.save_folder:
        st.session_state.recording = True
        filename = time.strftime("recording_%Y_%m_%d_%H_%M_%S.mp4")
        save_path = os.path.join(st.session_state.save_folder, filename)
        height, width = frame.shape[:2]
        fps = 20
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        st.session_state.video_writer = cv2.VideoWriter(save_path, fourcc, fps, (width, height))
        return True
    return False

# H√†m d·ª´ng ghi video
def stop_recording():
    """D·ª´ng ghi video"""
    if st.session_state.recording and st.session_state.video_writer:
        st.session_state.video_writer.release()
        st.session_state.video_writer = None
        st.session_state.recording = False
        return True
    return False

# X·ª≠ l√Ω theo ch·∫ø ƒë·ªô
if mode == "üìπ Camera":
    st.subheader("üìπ Ch·∫ø ƒë·ªô Camera")
    
    # N√∫t ƒëi·ªÅu khi·ªÉn camera
    col_btn1, col_btn2, col_btn3 = st.columns(3)
    
    with col_btn1:
        if st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu Camera", type="primary"):
            if st.session_state.video_capture is None:
                st.session_state.video_capture = cv2.VideoCapture(0)
                if st.session_state.video_capture.isOpened():
                    st.session_state.camera_active = True
                    st.session_state.current_status = "ƒêang ch·∫°y"
                    st.success("‚úÖ Camera ƒë√£ ƒë∆∞·ª£c kh·ªüi ƒë·ªông!")
                else:
                    st.error("‚ùå Kh√¥ng th·ªÉ m·ªü camera. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.")
            else:
                st.session_state.camera_active = True
                st.session_state.current_status = "ƒêang ch·∫°y"
    
    with col_btn2:
        if st.button("‚èπÔ∏è D·ª´ng Camera"):
            st.session_state.camera_active = False
            if st.session_state.video_capture:
                st.session_state.video_capture.release()
                st.session_state.video_capture = None
            stop_recording()
            st.session_state.current_status = "ƒê√£ d·ª´ng"
            st.info("‚èπÔ∏è Camera ƒë√£ ƒë∆∞·ª£c d·ª´ng.")
    
    with col_btn3:
        if st.button("üîÑ Reset"):
            st.session_state.fall_count = 0
            st.session_state.fall_history = []
            st.session_state.current_status = "ƒê√£ reset"
            st.success("üîÑ ƒê√£ reset th·ªëng k√™!")
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i
    status_col1, status_col2 = st.columns([3, 1])
    
    with status_col1:
        status_placeholder = st.empty()
    
    with status_col2:
        metric_placeholder = st.empty()
    
    # Hi·ªÉn th·ªã video
    video_placeholder = st.empty()
    
    # S·ª≠ d·ª•ng st.camera_input cho camera ·ªïn ƒë·ªãnh h∆°n
    if st.session_state.camera_active:
        camera_input = st.camera_input("Camera ƒëang ho·∫°t ƒë·ªông", key="camera_stream")
        
        if camera_input is not None:
            try:
                # Chuy·ªÉn ƒë·ªïi t·ª´ PIL Image sang numpy array
                if isinstance(camera_input, Image.Image):
                    img_array = np.array(camera_input.convert('RGB'))
                else:
                    camera_input.seek(0)
                    img_pil = Image.open(camera_input)
                    img_array = np.array(img_pil.convert('RGB'))
                
                # Ki·ªÉm tra ƒë·ªãnh d·∫°ng v√† chuy·ªÉn ƒë·ªïi
                if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                    # ƒê·∫£m b·∫£o l√† uint8
                    if img_array.dtype != np.uint8:
                        if img_array.max() <= 1.0:
                            img_array = (img_array * 255).astype(np.uint8)
                        else:
                            img_array = img_array.astype(np.uint8)
                    
                    # Chuy·ªÉn ƒë·ªïi RGB sang BGR cho OpenCV
                    img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                    
                    # X·ª≠ l√Ω frame
                    img_result, is_fall = process_frame(img_bgr)
                    
                    # C·∫≠p nh·∫≠t th·ªëng k√™ n·∫øu ph√°t hi·ªán ng√£
                    if is_fall:
                        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        # Ch·ªâ th√™m v√†o l·ªãch s·ª≠ n·∫øu ch∆∞a c√≥ trong 1 gi√¢y g·∫ßn nh·∫•t
                        if not st.session_state.fall_history or \
                           (datetime.now() - datetime.strptime(st.session_state.fall_history[-1], "%Y-%m-%d %H:%M:%S")).total_seconds() > 1:
                            st.session_state.fall_count += 1
                            st.session_state.fall_history.append(current_time)
                            st.session_state.last_fall_time = time.time()
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)
                        st.image(img_result_rgb, caption="K·∫øt qu·∫£ ph√°t hi·ªán", use_container_width=True)
                    
                    with col2:
                        # Hi·ªÉn th·ªã tr·∫°ng th√°i v·ªõi c·∫£nh b√°o r√µ r√†ng (kh√¥ng nh·∫•p nh√°y)
                        if is_fall:
                            status_placeholder.markdown(
                                f"""
                                <div style='text-align: center; padding: 20px; background-color: #ff4444; border-radius: 10px; border: 5px solid #ff0000;'>
                                    <h1 style='color: white; font-size: 48px; margin: 0;'>üö® C·∫¢NH B√ÅO!</h1>
                                    <h2 style='color: white; font-size: 32px; margin: 10px 0;'>PH√ÅT HI·ªÜN NG√É</h2>
                                    <p style='color: white; font-size: 18px; margin: 5px 0;'>Th·ªùi gian: {datetime.now().strftime("%H:%M:%S")}</p>
                                    <p style='color: white; font-size: 16px; margin: 5px 0; font-weight: bold;'>VUI L√íNG KI·ªÇM TRA NGAY!</p>
                                </div>
                                """,
                                unsafe_allow_html=True
                            )
                            metric_placeholder.metric("Tr·∫°ng th√°i", "üö® NG√É", delta="C·∫£nh b√°o", delta_color="inverse")
                            
                            # Hi·ªáu ·ª©ng ch·ªâ ch·∫°y m·ªôt l·∫ßn
                            if 'last_fall_display' not in st.session_state or st.session_state.last_fall_display != current_time:
                                st.balloons()
                                st.session_state.last_fall_display = current_time
                        else:
                            status_placeholder.markdown(
                                f"""
                                <div style='text-align: center; padding: 20px; background-color: #44ff44; border-radius: 10px;'>
                                    <h2 style='color: white; font-size: 32px; margin: 0;'>‚úÖ B√¨nh th∆∞·ªùng</h2>
                                    <p style='color: white; font-size: 16px; margin: 5px 0;'>Th·ªùi gian: {datetime.now().strftime("%H:%M:%S")}</p>
                                </div>
                                """,
                                unsafe_allow_html=True
                            )
                            metric_placeholder.metric("Tr·∫°ng th√°i", "‚úÖ B√¨nh th∆∞·ªùng", delta=None)
                        
                        # X·ª≠ l√Ω ghi video t·ª± ƒë·ªông
                        if auto_record and st.session_state.save_folder:
                            if is_fall:
                                if not st.session_state.recording:
                                    start_recording(img_bgr)
                                if st.session_state.video_writer:
                                    st.session_state.video_writer.write(img_bgr)
                            else:
                                # D·ª´ng ghi sau 2 gi√¢y kh√¥ng ph√°t hi·ªán ng√£
                                if st.session_state.recording:
                                    if st.session_state.last_fall_time:
                                        if time.time() - st.session_state.last_fall_time > 2:
                                            stop_recording()
                            
                            # Hi·ªÉn th·ªã tr·∫°ng th√°i ghi
                            if st.session_state.recording:
                                st.sidebar.warning("üî¥ ƒêang ghi video...")
                            else:
                                st.sidebar.info("‚è∏Ô∏è Kh√¥ng ghi")
                else:
                    st.error(f"‚ùå L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω h√¨nh ·∫£nh t·ª´ camera. Shape: {img_array.shape if 'img_array' in locals() else 'N/A'}")
            except Exception as e:
                st.error(f"‚ùå L·ªói x·ª≠ l√Ω camera: {str(e)}")
                st.exception(e)
    else:
        # Hi·ªÉn th·ªã placeholder khi camera ch∆∞a b·∫≠t
        st.info("üëÜ Nh·∫•n 'B·∫Øt ƒë·∫ßu Camera' ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√°t hi·ªán ng√£")
        video_placeholder.image("GUI/images/backgroud-placeholder.png" if os.path.exists("GUI/images/backgroud-placeholder.png") else None, 
                               caption="Camera ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông", use_container_width=True)

elif mode == "üìÅ Video File":
    st.subheader("üìÅ Ch·∫ø ƒë·ªô Video File")
    
    uploaded_file = st.file_uploader(
        "Ch·ªçn file video",
        type=['mp4', 'avi', 'mov', 'mkv']
    )
    
    if uploaded_file is not None:
        # L∆∞u file t·∫°m
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_file.read())
        tfile.close()
        
        # M·ªü video
        video_capture = cv2.VideoCapture(tfile.name)
        
        if not video_capture.isOpened():
            st.error("‚ùå Kh√¥ng th·ªÉ m·ªü file video.")
        else:
            st.success("‚úÖ Video ƒë√£ ƒë∆∞·ª£c t·∫£i!")
            
            # L·∫•y th√¥ng tin video
            fps = int(video_capture.get(cv2.CAP_PROP_FPS)) or 30
            total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # Thanh ti·∫øn tr√¨nh
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Hi·ªÉn th·ªã video
            video_placeholder = st.empty()
            
            frame_count = 0
            fall_detected_in_video = False
            
            while True:
                ret, frame = video_capture.read()
                if not ret:
                    break
                
                # X·ª≠ l√Ω frame
                try:
                    img_result, is_fall = process_frame(frame)
                    
                    if is_fall:
                        fall_detected_in_video = True
                        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        if not st.session_state.fall_history or \
                           (datetime.now() - datetime.strptime(st.session_state.fall_history[-1], "%Y-%m-%d %H:%M:%S")).total_seconds() > 1:
                            st.session_state.fall_count += 1
                            st.session_state.fall_history.append(current_time)
                    
                    # Hi·ªÉn th·ªã
                    img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)
                    video_placeholder.image(img_result_rgb, channels="RGB", use_container_width=True)
                    
                    # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh
                    frame_count += 1
                    progress = frame_count / total_frames if total_frames > 0 else 0
                    progress_bar.progress(progress)
                    
                    # Hi·ªÉn th·ªã tr·∫°ng th√°i
                    if is_fall:
                        status_text.markdown(
                            f"""
                            <div style='text-align: center; padding: 15px; background-color: #ff4444; border-radius: 10px; border: 3px solid #ff0000;'>
                                <h2 style='color: white; font-size: 24px; margin: 0;'>üö® PH√ÅT HI·ªÜN NG√É!</h2>
                                <p style='color: white; font-size: 14px; margin: 5px 0;'>Frame {frame_count}/{total_frames} - Th·ªùi gian: {datetime.now().strftime('%H:%M:%S')}</p>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
                    else:
                        status_text.markdown(
                            f"""
                            <div style='text-align: center; padding: 15px; background-color: #44ff44; border-radius: 10px;'>
                                <h2 style='color: white; font-size: 24px; margin: 0;'>‚úÖ B√¨nh th∆∞·ªùng</h2>
                                <p style='color: white; font-size: 14px; margin: 5px 0;'>Frame {frame_count}/{total_frames}</p>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
                    
                    time.sleep(1.0 / fps)  # Gi·ªØ t·ªëc ƒë·ªô video g·ªëc
                except Exception as e:
                    st.error(f"‚ùå L·ªói x·ª≠ l√Ω frame: {str(e)}")
                    break
            
            video_capture.release()
            os.unlink(tfile.name)
            
            if fall_detected_in_video:
                st.error("üö® **ƒê√£ ph√°t hi·ªán ng√£ trong video!**")
            else:
                st.success("‚úÖ **Kh√¥ng ph√°t hi·ªán ng√£ trong video**")

elif mode == "üñºÔ∏è Image":
    st.subheader("üñºÔ∏è Ch·∫ø ƒë·ªô H√¨nh ·∫£nh")
    
    uploaded_file = st.file_uploader(
        "Ch·ªçn h√¨nh ·∫£nh",
        type=['jpg', 'jpeg', 'png']
    )
    
    if uploaded_file is not None:
        # ƒê·ªçc h√¨nh ·∫£nh
        image = Image.open(uploaded_file)
        img_array = np.array(image)
        
        # Chuy·ªÉn ƒë·ªïi RGB sang BGR cho OpenCV
        if len(img_array.shape) == 3:
            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = img_array
        
        # X·ª≠ l√Ω
        try:
            img_result, is_fall = process_frame(img_bgr)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(image, caption="H√¨nh ·∫£nh g·ªëc", use_container_width=True)
            
            with col2:
                img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)
                st.image(img_result_rgb, caption="K·∫øt qu·∫£ ph√°t hi·ªán", use_container_width=True)
            
            # Hi·ªÉn th·ªã tr·∫°ng th√°i
            if is_fall:
                st.markdown(
                    f"""
                    <div style='text-align: center; padding: 20px; background-color: #ff4444; border-radius: 10px; border: 5px solid #ff0000;'>
                        <h1 style='color: white; font-size: 48px; margin: 0; animation: blink 1s infinite;'>üö® C·∫¢NH B√ÅO!</h1>
                        <h2 style='color: white; font-size: 32px; margin: 10px 0;'>PH√ÅT HI·ªÜN NG√É</h2>
                        <p style='color: white; font-size: 18px; margin: 5px 0;'>Th·ªùi gian: {datetime.now().strftime("%H:%M:%S")}</p>
                    </div>
                    <style>
                        @keyframes blink {{
                            0%, 100% {{ opacity: 1; }}
                            50% {{ opacity: 0.5; }}
                        }}
                    </style>
                    """,
                    unsafe_allow_html=True
                )
                st.balloons()
            else:
                st.markdown(
                    f"""
                    <div style='text-align: center; padding: 20px; background-color: #44ff44; border-radius: 10px;'>
                        <h2 style='color: white; font-size: 32px; margin: 0;'>‚úÖ B√¨nh th∆∞·ªùng</h2>
                        <p style='color: white; font-size: 16px; margin: 5px 0;'>Kh√¥ng ph√°t hi·ªán ng√£ trong h√¨nh ·∫£nh</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
        except Exception as e:
            st.error(f"‚ùå L·ªói x·ª≠ l√Ω h√¨nh ·∫£nh: {str(e)}")
            st.exception(e)

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        <p>FallSense - Ph√°t hi·ªán ng√£ v√† ƒë·ªôt qu·ªµ s·ª≠ d·ª•ng YOLOv7</p>
        <p>Powered by PyTorch & Streamlit</p>
    </div>
    """,
    unsafe_allow_html=True
)
